{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6097cf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Basic imports successful\n",
      "Python version: 3.12.11 (main, Aug  8 2025, 17:06:48) [Clang 20.1.4 ]\n",
      "Current directory: /home/jroberts/fon_proposal_writer\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Core imports and path setup\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.insert(0, os.path.abspath('.'))\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"✅ Basic imports successful\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d580cc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AZURE_API_KEY: ✅ Set\n",
      "AZURE_API_BASE: ✅ Set\n",
      "AZURE_OPENAI_DEPLOYMENT: ✅ Set\n",
      "LANGFUSE_PUBLIC_KEY: ✅ Set\n",
      "LANGFUSE_SECRET_KEY: ✅ Set\n",
      "AZURE_STORAGE_CONNECTION_STRING: ✅ Set\n",
      "\n",
      "✅ All required environment variables are set\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load and verify environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Check critical environment variables\n",
    "env_vars = {\n",
    "    \"AZURE_API_KEY\": os.getenv(\"AZURE_API_KEY\"),\n",
    "    \"AZURE_API_BASE\": os.getenv(\"AZURE_API_BASE\"),\n",
    "    \"AZURE_OPENAI_DEPLOYMENT\": os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    \"LANGFUSE_PUBLIC_KEY\": os.getenv(\"LANGFUSE_PUBLIC_KEY\"),\n",
    "    \"LANGFUSE_SECRET_KEY\": os.getenv(\"LANGFUSE_SECRET_KEY\"),\n",
    "    \"AZURE_STORAGE_CONNECTION_STRING\": os.getenv(\"AZURE_STORAGE_CONNECTION_STRING\"),\n",
    "}\n",
    "\n",
    "# Display status (hide actual values)\n",
    "for key, value in env_vars.items():\n",
    "    status = \"✅ Set\" if value else \"❌ Missing\"\n",
    "    print(f\"{key}: {status}\")\n",
    "    \n",
    "missing = [k for k, v in env_vars.items() if not v]\n",
    "if missing:\n",
    "    print(f\"\\n⚠️ Missing environment variables: {', '.join(missing)}\")\n",
    "else:\n",
    "    print(\"\\n✅ All required environment variables are set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4da7567a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "  Azure Deployment: gpt-4.1\n",
      "  Langfuse Host: https://us.cloud.langfuse.com\n",
      "  Blob Container: rfp-poc\n",
      "  Debug Mode: False\n",
      "\n",
      "  Constructed endpoint: https://proposal-openai-model.openai.azure.com//openai/v1/\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Test configuration module\n",
    "from src.config import settings\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"  Azure Deployment: {settings.azure_openai_deployment}\")\n",
    "print(f\"  Langfuse Host: {settings.langfuse_host}\")\n",
    "print(f\"  Blob Container: {settings.azure_blob_container}\")\n",
    "print(f\"  Debug Mode: {settings.debug}\")\n",
    "\n",
    "# Verify Azure OpenAI endpoint construction\n",
    "endpoint = f\"{settings.azure_api_base}/openai/v1/\"\n",
    "print(f\"\\n  Constructed endpoint: {endpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e520e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "def download_zip_file():\n",
    "    \"\"\"Download DHS_CBP.zip from Azure Blob Storage\"\"\"\n",
    "    \n",
    "    # Initialize the BlobServiceClient using connection string\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(\n",
    "        os.getenv(\"AZURE_STORAGE_CONNECTION_STRING\")\n",
    "    )\n",
    "    \n",
    "    # You need to know the container name - common names are:\n",
    "    # \"data\", \"files\", \"uploads\", \"rfp-poc\", etc.\n",
    "    container_name = \"rfp-poc\"  # Replace with your actual container name\n",
    "    blob_name = \"DHS_CBP.zip\"\n",
    "    local_file_path = \"./DHS_CBP.zip\"  # Where to save locally\n",
    "    \n",
    "    try:\n",
    "        # Get blob client\n",
    "        blob_client = blob_service_client.get_blob_client(\n",
    "            container=container_name, \n",
    "            blob=blob_name\n",
    "        )\n",
    "        \n",
    "        # Download the blob\n",
    "        print(f\"Downloading {blob_name}...\")\n",
    "        with open(local_file_path, \"wb\") as download_file:\n",
    "            download_data = blob_client.download_blob()\n",
    "            download_file.write(download_data.readall())\n",
    "        \n",
    "        print(f\"✅ Successfully downloaded to {local_file_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error downloading file: {e}\")\n",
    "        \n",
    "        # If container name is wrong, list available containers\n",
    "        if \"ContainerNotFound\" in str(e):\n",
    "            print(\"\\nAvailable containers:\")\n",
    "            for container in blob_service_client.list_containers():\n",
    "                print(f\"  - {container.name}\")\n",
    "\n",
    "# Run the download\n",
    "download_zip_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e887b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# Unzip the file to current directory\n",
    "with zipfile.ZipFile('./data/inputs/DHS_CBP.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./data/inputs/')  # '.' means current directory\n",
    "\n",
    "print(\"✅ Unzipped all files to current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e412de54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded PDF: data/inputs/DHS_CBP/RFP-RFQ/06C25R0054_RFP_RABAS_HCaTS_RFP_Letter.pdf\n",
      "  Number of pages: 57\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Test PDF loader\n",
    "from src.io.loaders import pdf_to_pages\n",
    "\n",
    "# Create a test PDF or use an existing one\n",
    "test_pdf_path = \"data/inputs/DHS_CBP/RFP-RFQ/06C25R0054_RFP_RABAS_HCaTS_RFP_Letter.pdf\"\n",
    "\n",
    "if Path(test_pdf_path).exists():\n",
    "    pages = pdf_to_pages(test_pdf_path)\n",
    "    print(f\"✅ Successfully loaded PDF: {test_pdf_path}\")\n",
    "    print(f\"  Number of pages: {len(pages)}\")\n",
    "    # print(f\"  First page preview (first 500 chars):\")\n",
    "    # if pages:\n",
    "    #     print(f\"  {pages[0][1][:500]}...\")\n",
    "else:\n",
    "    print(f\"❌ Test PDF not found at: {test_pdf_path}\")\n",
    "    print(\"  Create a test PDF or update the path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "043919a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created 57 chunks\n",
      "\n",
      "Chunk 1:\n",
      "  Pages: 1-2\n",
      "  Section: Owned Small Business Program\n",
      "\n",
      "Chunk 2:\n",
      "  Pages: 2-3\n",
      "  Section: B. INSTRUCTIONS TO QUOTERS\n",
      "\n",
      "Chunk 3:\n",
      "  Pages: 3-4\n",
      "  Section: Six pages\n",
      "\n",
      "Chunk 4:\n",
      "  Pages: 4-5\n",
      "  Section: Prior experience with government entities is preferred.\n",
      "\n",
      "Chunk 5:\n",
      "  Pages: 5-6\n",
      "  Section: SOW.\n",
      "\n",
      "Chunk 6:\n",
      "  Pages: 6-7\n",
      "  Section: Failure to comply with this requirement may result in the quote being deemed non-\n",
      "\n",
      "Chunk 7:\n",
      "  Pages: 7-8\n",
      "  Section: Failure to comply with this requirement may result in the quote being deemed non-\n",
      "\n",
      "Chunk 8:\n",
      "  Pages: 8-9\n",
      "  Section: C. EVALUATION FACTORS AND BASIS FOR AWARD\n",
      "\n",
      "Chunk 9:\n",
      "  Pages: 9-10\n",
      "  Section: Low Confidence The Government has low confidence that the Offeror\n",
      "\n",
      "Chunk 10:\n",
      "  Pages: 10-11\n",
      "  Section: See  clauses below.\n",
      "\n",
      "Chunk 11:\n",
      "  Pages: 11-12\n",
      "  Section: SECTION B DELIVERIES OR PERFORMANCE\n",
      "\n",
      "Chunk 12:\n",
      "  Pages: 12-13\n",
      "  Section: C.3 ELECTRONIC INVOICING AND PAYMENT REQUIREMENTS - INVOICE PROCESSING PLATFORM\n",
      "\n",
      "Chunk 13:\n",
      "  Pages: 13-14\n",
      "  Section: Login.gov.\n",
      "\n",
      "Chunk 14:\n",
      "  Pages: 14-15\n",
      "  Section: Login.gov.\n",
      "\n",
      "Chunk 15:\n",
      "  Pages: 15-16\n",
      "  Section: SECTION D SPECIAL CONTRACT REQUIREMENTS\n",
      "\n",
      "Chunk 16:\n",
      "  Pages: 16-17\n",
      "  Section: SECTION D SPECIAL CONTRACT REQUIREMENTS\n",
      "\n",
      "Chunk 17:\n",
      "  Pages: 17-18\n",
      "  Section: SECTION D SPECIAL CONTRACT REQUIREMENTS\n",
      "\n",
      "Chunk 18:\n",
      "  Pages: 18-19\n",
      "  Section: A.  CBP Suitability Requirements\n",
      "\n",
      "Chunk 19:\n",
      "  Pages: 19-20\n",
      "  Section: B.  Security Clearance Requirements\n",
      "\n",
      "Chunk 20:\n",
      "  Pages: 20-21\n",
      "  Section: C.  Contractor Tracking System\n",
      "\n",
      "Chunk 21:\n",
      "  Pages: 21-22\n",
      "  Section: A.  Access Controls.\n",
      "\n",
      "Chunk 22:\n",
      "  Pages: 22-23\n",
      "  Section: A.  Managing Sensitive Security Information.\n",
      "\n",
      "Chunk 23:\n",
      "  Pages: 23-24\n",
      "  Section: B.  Managing Classified Information.\n",
      "\n",
      "Chunk 24:\n",
      "  Pages: 24-25\n",
      "  Section: V.  NOTIFICATION OF CONTRACTOR EMPLOYEE CHANGES\n",
      "\n",
      "Chunk 25:\n",
      "  Pages: 25-26\n",
      "  Section: C. Privacy Act\n",
      "\n",
      "Chunk 26:\n",
      "  Pages: 26-27\n",
      "  Section: C. Privacy Act\n",
      "\n",
      "Chunk 27:\n",
      "  Pages: 27-28\n",
      "  Section: Washington DC.\n",
      "\n",
      "Chunk 28:\n",
      "  Pages: 28-29\n",
      "  Section: Washington DC.\n",
      "\n",
      "Chunk 29:\n",
      "  Pages: 29-30\n",
      "  Section: Washington DC.\n",
      "\n",
      "Chunk 30:\n",
      "  Pages: 30-31\n",
      "  Section: B. Requirements\n",
      "\n",
      "Chunk 31:\n",
      "  Pages: 31-32\n",
      "  Section: Safeguarding Sensitive Personally Identifiable Information.\n",
      "\n",
      "Chunk 32:\n",
      "  Pages: 32-33\n",
      "  Section: D. Subcontracts\n",
      "\n",
      "Chunk 33:\n",
      "  Pages: 33-34\n",
      "  Section: E.5 52.219-4 NOTICE OF PRICE EVALUATION PREFERENCE FOR HUBZONE SMALL BUSINESS\n",
      "\n",
      "Chunk 34:\n",
      "  Pages: 34-35\n",
      "  Section: 60 months.\n",
      "\n",
      "Chunk 35:\n",
      "  Pages: 35-36\n",
      "  Section: 60 months.\n",
      "\n",
      "Chunk 36:\n",
      "  Pages: 36-37\n",
      "  Section: 60 months.\n",
      "\n",
      "Chunk 37:\n",
      "  Pages: 37-38\n",
      "  Section: 60 months.\n",
      "\n",
      "Chunk 38:\n",
      "  Pages: 38-39\n",
      "  Section: 60 months.\n",
      "\n",
      "Chunk 39:\n",
      "  Pages: 39-40\n",
      "  Section: 60 months.\n",
      "\n",
      "Chunk 40:\n",
      "  Pages: 40-41\n",
      "  Section: 60 months.\n",
      "\n",
      "Chunk 41:\n",
      "  Pages: 41-42\n",
      "  Section: 60 months.\n",
      "\n",
      "Chunk 42:\n",
      "  Pages: 42-43\n",
      "  Section: 60 months.\n",
      "\n",
      "Chunk 43:\n",
      "  Pages: 43-44\n",
      "  Section: 60 months.\n",
      "\n",
      "Chunk 44:\n",
      "  Pages: 44-45\n",
      "  Section: HSAR 3052.204-72 Safeguarding of controlled unclassified information.\n",
      "\n",
      "Chunk 45:\n",
      "  Pages: 45-46\n",
      "  Section: HSAR 3052.204-72 Safeguarding of controlled unclassified information.\n",
      "\n",
      "Chunk 46:\n",
      "  Pages: 46-47\n",
      "  Section: HSAR 3052.204-72 Safeguarding of controlled unclassified information.\n",
      "\n",
      "Chunk 47:\n",
      "  Pages: 47-48\n",
      "  Section: HSAR 3052.204-72 Safeguarding of controlled unclassified information.\n",
      "\n",
      "Chunk 48:\n",
      "  Pages: 48-49\n",
      "  Section: HSAR 3052.204-72 Safeguarding of controlled unclassified information.\n",
      "\n",
      "Chunk 49:\n",
      "  Pages: 49-50\n",
      "  Section: HSAR 3052.204-72 Safeguarding of controlled unclassified information.\n",
      "\n",
      "Chunk 50:\n",
      "  Pages: 50-51\n",
      "  Section: U.S. Government requirements.\n",
      "\n",
      "Chunk 51:\n",
      "  Pages: 51-52\n",
      "  Section: SA package and may limit the number of resubmissions of modified documents.\n",
      "\n",
      "Chunk 52:\n",
      "  Pages: 52-53\n",
      "  Section: SA package and may limit the number of resubmissions of modified documents.\n",
      "\n",
      "Chunk 53:\n",
      "  Pages: 53-54\n",
      "  Section: Attachment No. 2 Pricing Template\n",
      "\n",
      "Chunk 54:\n",
      "  Pages: 54-55\n",
      "  Section: G.3 52.225-20 PROHIBITION ON CONDUCTING RESTRICTED BUSINESS OPERATIONS IN\n",
      "\n",
      "Chunk 55:\n",
      "  Pages: 55-56\n",
      "  Section: G.3 52.225-20 PROHIBITION ON CONDUCTING RESTRICTED BUSINESS OPERATIONS IN\n",
      "\n",
      "Chunk 56:\n",
      "  Pages: 56-57\n",
      "  Section: G.3 52.225-20 PROHIBITION ON CONDUCTING RESTRICTED BUSINESS OPERATIONS IN\n",
      "\n",
      "Chunk 57:\n",
      "  Pages: 57-57\n",
      "  Section: G.3 52.225-20 PROHIBITION ON CONDUCTING RESTRICTED BUSINESS OPERATIONS IN\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Test heading-aware chunking\n",
    "from src.preprocessing.segmenter import heading_aware_chunks\n",
    "\n",
    "# Use the pages from previous cell or create test data\n",
    "if 'pages' not in locals():\n",
    "    # Create dummy test data\n",
    "    pages = [\n",
    "        (1, \"Section 1. Introduction\\n\\nThe contractor SHALL deliver all documentation in PDF format. Font size MUST be 12pt Times New Roman.\\n\\n\"),\n",
    "        (2, \"Section 2. Requirements\\n\\nThe system SHOULD support 1000 concurrent users. Response time MUST NOT exceed 2 seconds.\\n\\n\")\n",
    "    ]\n",
    "\n",
    "chunks = list(heading_aware_chunks(pages, max_chars=1000, overlap=100))\n",
    "\n",
    "print(f\"✅ Created {len(chunks)} chunks\")\n",
    "for i, chunk in enumerate(chunks):  # Show first 3 chunks\n",
    "    print(f\"\\nChunk {i+1}:\")\n",
    "    print(f\"  Pages: {chunk['start_page']}-{chunk['end_page']}\")\n",
    "    print(f\"  Section: {chunk['section']}\")\n",
    "    # print(f\"  Text preview: {chunk['text'][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17cd2a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 2 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 1 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 1 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 1 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 1 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 3 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 1 regex matches:\n",
      "✅ Found 1 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 1 regex matches:\n",
      "✅ Found 1 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 2 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 1 regex matches:\n",
      "✅ Found 1 regex matches:\n",
      "✅ Found 0 regex matches:\n",
      "✅ Found 17 regex matches:\n",
      "  - Type: deadline\n",
      "    Match: Due Date:  7/17/2025\n",
      "\n",
      "  - Type: deadline\n",
      "    Match: Due Date:  8/4/2025\n",
      "\n",
      "  - Type: certification\n",
      "    Match: Certification\n",
      "\n",
      "  - Type: deadline\n",
      "    Match: submitted via email with all other quote volumes on or \n",
      "before 7/31/2025\n",
      "\n",
      "  - Type: deadline\n",
      "    Match: submit information and \n",
      "documentation requested by CBP to initiate the background investigation proc\n",
      "\n",
      "  - Type: certification\n",
      "    Match: certify\n",
      "\n",
      "  - Type: certification\n",
      "    Match: certification\n",
      "\n",
      "  - Type: certification\n",
      "    Match: certification\n",
      "\n",
      "  - Type: certification\n",
      "    Match: certification\n",
      "\n",
      "  - Type: certification\n",
      "    Match: certification\n",
      "\n",
      "  - Type: certification\n",
      "    Match: certification\n",
      "\n",
      "  - Type: certification\n",
      "    Match: certification\n",
      "\n",
      "  - Type: certification\n",
      "    Match: certification\n",
      "\n",
      "  - Type: certification\n",
      "    Match: certify\n",
      "\n",
      "  - Type: certification\n",
      "    Match: certification\n",
      "\n",
      "  - Type: certification\n",
      "    Match: CERTIFICATION\n",
      "\n",
      "  - Type: certification\n",
      "    Match: Certification\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Test regex pre-pass\n",
    "from src.preprocessing.regex_pass import fast_hits\n",
    "\n",
    "# Test with sample chunks\n",
    "test_chunk = {\n",
    "    \"text\": \"\"\"The contractor SHALL submit monthly reports by the 15th of each month.\n",
    "    All deliverables MUST be submitted by 12/31/2024.\n",
    "    System SHALL be ISO 27001 certified.\n",
    "    Technical evaluation worth 60 points.\"\"\",\n",
    "    \"section\": \"Submission Requirements\",\n",
    "    \"start_page\": 1,\n",
    "    \"end_page\": 1\n",
    "}\n",
    "\n",
    "all_matches = []\n",
    "for chunk in chunks:\n",
    "    matches = fast_hits(chunk)\n",
    "    print(f\"✅ Found {len(matches)} regex matches:\")\n",
    "    all_matches.extend(matches)\n",
    "print(f\"✅ Found {len(all_matches)} regex matches:\")\n",
    "for match in all_matches:\n",
    "    print(f\"  - Type: {match['kind']}\")\n",
    "    print(f\"    Match: {match['match'][:100]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d3487836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DSPy configured with model: azure/gpt-4.1\n",
      "✅ DSPy test successful: 5 + 3 equals 8.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Initialize DSPy with Azure OpenAI\n",
    "import dspy\n",
    "from src.config import settings\n",
    "\n",
    "# Configure DSPy\n",
    "lm = dspy.LM(\n",
    "    model=settings.azure_openai_deployment,\n",
    "    api_key=settings.azure_api_key,\n",
    "    api_base=f\"{settings.azure_api_base}/openai/v1/\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=32700\n",
    ")\n",
    "\n",
    "# Set up with JSON adapter for structured output\n",
    "dspy.configure(lm=lm, adapter=dspy.JSONAdapter(), track_usage=True, cache=True)\n",
    "# dspy.configure_cache(\n",
    "#     enable_disk_cache=False,\n",
    "#     enable_memory_cache=False,\n",
    "# )\n",
    "\n",
    "print(f\"✅ DSPy configured with model: azure/{settings.azure_openai_deployment}\")\n",
    "\n",
    "# Test with a simple prompt\n",
    "test_lm = dspy.Predict(\"question -> answer\")\n",
    "try:\n",
    "    result = test_lm(question=\"What is 5+3?\")\n",
    "    print(f\"✅ DSPy test successful: {result.answer}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ DSPy test failed: {e}\")\n",
    "    print(\"API Base:\", settings.azure_api_base)\n",
    "    print(\"Deployment:\", settings.azure_openai_deployment)\n",
    "    print(\"API Key set:\", bool(settings.azure_api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc2a45b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-31 22:17:32,318 - src.observability.tracing - INFO - Tracing initialized with Langfuse host: https://us.cloud.langfuse.com\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Langfuse tracing initialized\n",
      "  Host: https://us.cloud.langfuse.com\n",
      "✅ Test trace created: Test successful\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Initialize Langfuse tracing\n",
    "from src.observability.tracing import initialize_tracing, get_langfuse_client\n",
    "\n",
    "try:\n",
    "    langfuse_client = initialize_tracing()\n",
    "    print(\"✅ Langfuse tracing initialized\")\n",
    "    print(f\"  Host: {settings.langfuse_host}\")\n",
    "    \n",
    "    # Create a test trace\n",
    "    from langfuse import observe\n",
    "    \n",
    "    @observe(name=\"test_function\")\n",
    "    def test_trace():\n",
    "        return \"Test successful\"\n",
    "    \n",
    "    result = test_trace()\n",
    "    langfuse_client.flush()\n",
    "    print(f\"✅ Test trace created: {result}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Langfuse initialization warning: {e}\")\n",
    "    print(\"  Continuing without tracing...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0abc01a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing last 1 chunks (pages 46-47)\n",
      "Sections covered: ['HSAR 3052.204-72 Safeguarding of controlled unclassified information.']\n",
      "\n",
      "Processing chunk 1/10 (pages 46-47, section: HSAR 3052.204-72 Safeguarding of controlled unclas...)\n",
      "  ⚠️ Extraction failed: 'list' object has no attribute 'set_lm_usage'\n",
      "\n",
      "✅ Total extracted: 0 requirements from last 10 chunks\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Extract requirements from the last 10 chunks of your RFP\n",
    "from src.extraction.modules import Extractor\n",
    "import json\n",
    "\n",
    "# Initialize extractor\n",
    "extractor = Extractor()\n",
    "\n",
    "# Take the last 10 chunks (likely containing submission requirements, terms, etc.)\n",
    "last_chunks = chunks[-12:-11]\n",
    "print(f\"Processing last {len(last_chunks)} chunks (pages {last_chunks[0]['start_page']}-{last_chunks[-1]['end_page']})\")\n",
    "print(f\"Sections covered: {[c['section'] for c in last_chunks]}\\n\")\n",
    "\n",
    "# Extract requirements from each chunk\n",
    "all_extracted = []\n",
    "for i, chunk in enumerate(last_chunks):\n",
    "    print(f\"Processing chunk {i+1}/10 (pages {chunk['start_page']}-{chunk['end_page']}, section: {chunk['section'][:50]}...)\")\n",
    "    try:\n",
    "        requirements = extractor(chunk)\n",
    "        all_extracted.extend(requirements)\n",
    "        print(f\"  → Found {len(requirements)} requirements\")\n",
    "        for req in requirements[:2]:  # Show first 2 from each chunk\n",
    "            print(f\"    • {req.get('label', 'No label')[:80]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠️ Extraction failed: {e}\")\n",
    "\n",
    "print(f\"\\n✅ Total extracted: {len(all_extracted)} requirements from last 10 chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f3d45fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache methods and attributes:\n",
      "  cache_key\n",
      "  disk_cache\n",
      "  enable_disk_cache\n",
      "  enable_memory_cache\n",
      "  get\n",
      "  load_memory_cache\n",
      "  memory_cache\n",
      "  put\n",
      "  reset_memory_cache\n",
      "  save_memory_cache\n",
      "\n",
      "All cache attributes (including private):\n",
      "  _lock: <class '_thread.RLock'>\n",
      "  disk_cache: <class 'diskcache.fanout.FanoutCache'>\n",
      "  enable_disk_cache: <class 'bool'>\n",
      "  enable_memory_cache: <class 'bool'>\n",
      "  memory_cache: <class 'cachetools.LRUCache'>\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "# See what methods the cache has\n",
    "print(\"Cache methods and attributes:\")\n",
    "for attr in dir(dspy.cache):\n",
    "    if not attr.startswith('_'):\n",
    "        print(f\"  {attr}\")\n",
    "\n",
    "# Check for common cache patterns\n",
    "if hasattr(dspy.cache, 'cache'):\n",
    "    print(\"\\nFound cache.cache - type:\", type(dspy.cache.cache))\n",
    "    if hasattr(dspy.cache.cache, 'clear'):\n",
    "        dspy.cache.cache.clear()\n",
    "        print(\"✓ Cleared dspy.cache.cache\")\n",
    "\n",
    "if hasattr(dspy.cache, '_cache'):\n",
    "    print(\"\\nFound cache._cache - type:\", type(dspy.cache._cache))\n",
    "    if hasattr(dspy.cache._cache, 'clear'):\n",
    "        dspy.cache._cache.clear()\n",
    "        print(\"✓ Cleared dspy.cache._cache\")\n",
    "\n",
    "if hasattr(dspy.cache, 'data'):\n",
    "    print(\"\\nFound cache.data - type:\", type(dspy.cache.data))\n",
    "    if hasattr(dspy.cache.data, 'clear'):\n",
    "        dspy.cache.data.clear()\n",
    "        print(\"✓ Cleared dspy.cache.data\")\n",
    "\n",
    "# Try to see the internal structure\n",
    "print(\"\\nAll cache attributes (including private):\")\n",
    "for attr in dir(dspy.cache):\n",
    "    try:\n",
    "        value = getattr(dspy.cache, attr)\n",
    "        if not callable(value) and not attr.startswith('__'):\n",
    "            print(f\"  {attr}: {type(value)}\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ca6b6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory cache size: 0\n",
      "Disk cache size: 0\n",
      "✓ Memory cache reset\n",
      "✓ Disk cache cleared\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory cache size: {len(dspy.cache.memory_cache)}\")\n",
    "print(f\"Disk cache size: {len(dspy.cache.disk_cache)}\")\n",
    "\n",
    "\n",
    "# 1. Clear the memory cache\n",
    "dspy.cache.reset_memory_cache()\n",
    "print(\"✓ Memory cache reset\")\n",
    "\n",
    "# 2. Clear the disk cache\n",
    "dspy.cache.disk_cache.clear()\n",
    "print(\"✓ Disk cache cleared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5674854d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted requirements saved to ./test-results/extractor_2.json\n"
     ]
    }
   ],
   "source": [
    "test_type = \"extractor\"\n",
    "test_number = 2\n",
    "with open(f\"./test-results/{test_type}_test_{str(test_number)}.json\", \"x\") as f:\n",
    "    json.dump(all_extracted, f, indent=2)\n",
    "\n",
    "print(f\"Extracted requirements saved to ./test-results/{test_type}_{str(test_number)}.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fon_proposal_writer (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
